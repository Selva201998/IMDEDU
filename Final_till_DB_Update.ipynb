{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0477bf45-f57b-4446-bea0-ae2a7b1bc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np  # Add this import to resolve the error\n",
    "import matplotlib.pyplot as plt  # You also need to import matplotlib for plotting\n",
    "import pprint\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53976818-d8f7-4bee-8972-b8b77afadf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    failed_files = []  # To track files that couldn't be loaded\n",
    "    \n",
    "    # List all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Check if the file is an image (based on file extension)\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            try:\n",
    "                # Open the image using Pillow\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # Verify the image file integrity\n",
    "                images.append(file_path)  # Save the file path instead of the image object\n",
    "                print(f\"Loaded: {filename}\")\n",
    "            except Exception as e:\n",
    "                failed_files.append((filename, str(e)))\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images loaded: {len(images)}\")\n",
    "    print(f\"Failed to load: {len(failed_files)}\")\n",
    "    if failed_files:\n",
    "        print(\"\\nFailed Files:\")\n",
    "        for file, error in failed_files:\n",
    "            print(f\"{file}: {error}\")\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255ca71e-36c8-4480-85cf-d8d3dd76c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute SHA-256 hash for an image\n",
    "def compute_cryptographic_hash(image_path):\n",
    "    hash_sha256 = hashlib.sha256()  # Initialize SHA-256 hash object\n",
    "    \n",
    "    try:\n",
    "        # Open the image file in binary mode\n",
    "        with open(image_path, 'rb') as img_file:\n",
    "            # Read the image in chunks to avoid memory issues with large files\n",
    "            while chunk := img_file.read(8192):\n",
    "                hash_sha256.update(chunk)  # Update the hash with each chunk of data\n",
    "        \n",
    "        return hash_sha256.hexdigest()  # Return the hexadecimal representation of the hash\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing hash for {image_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5ddd8c-a513-4e23-a6f3-2b20d2e7ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: DSC_0172.JPG\n",
      "Loaded: DSC_0769.JPG\n",
      "Loaded: DSC_0777.JPG\n",
      "\n",
      "Summary:\n",
      "Total images loaded: 3\n",
      "Failed to load: 0\n"
     ]
    }
   ],
   "source": [
    "# Directory path where images are stored\n",
    "directory_path = r\"C:\\APPU SELVA\\temp\"\n",
    "\n",
    "# Load the images from the directory\n",
    "image_paths = load_images_from_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b3e99b-394a-4a16-850a-f43591f2fffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash for C:\\APPU SELVA\\temp\\DSC_0172.JPG: 9e422052fd039a43db88ce1a96759febfa60fee2111a7081b3fcb187c035092d\n",
      "Hash for C:\\APPU SELVA\\temp\\DSC_0769.JPG: 7623262c32c591f0aa586d17e0205457d2032347414dddf20035b3c216e99e35\n",
      "Hash for C:\\APPU SELVA\\temp\\DSC_0777.JPG: 7c5c213df376f81da6002acca512972b671f2d7e11e20aae125f470a556fc25b\n",
      "Image hashes could be computed:\n"
     ]
    }
   ],
   "source": [
    "# Compute hash for each image and print\n",
    "cryptographic_hashes = {}\n",
    "for image_path in image_paths:\n",
    "    img_hash = compute_cryptographic_hash(image_path)\n",
    "    if img_hash:\n",
    "        cryptographic_hashes[image_path] = img_hash\n",
    "        print(f\"Hash for {image_path}: {img_hash}\")\n",
    "\n",
    "# Example: Display all computed hashes\n",
    "if cryptographic_hashes:\n",
    "    print(\"Image hashes could be computed:\")\n",
    "else:\n",
    "    print(\"No images found or hashes could not be computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0c3491-9552-4b3a-ad9b-777635f45bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute perceptual hash for an image\n",
    "def compute_perceptual_hash(image):\n",
    "    try:\n",
    "        # Convert image to RGB (in case it's not in RGB format)\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Compute the perceptual hash using average hash method\n",
    "        perceptual_hash = imagehash.average_hash(image)\n",
    "        \n",
    "        return perceptual_hash\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing perceptual hash: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f511f7d8-4171-4180-84e7-5c6e83c23777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptual hash for C:\\APPU SELVA\\temp\\DSC_0172.JPG: bb9383818181c1ff\n",
      "Perceptual hash for C:\\APPU SELVA\\temp\\DSC_0769.JPG: 0723002727272727\n",
      "Perceptual hash for C:\\APPU SELVA\\temp\\DSC_0777.JPG: 2707818617072727\n"
     ]
    }
   ],
   "source": [
    "# Print perceptual hashes for all images\n",
    "perceptual_hashes = {}\n",
    "for image_path in image_paths:\n",
    "    try:\n",
    "        # Open the image using Pillow\n",
    "        with Image.open(image_path) as img:\n",
    "            # Compute perceptual hash for the image\n",
    "            perceptual_hash = compute_perceptual_hash(img)\n",
    "            if perceptual_hash:\n",
    "                perceptual_hashes[image_path] = perceptual_hash\n",
    "                print(f\"Perceptual hash for {image_path}: {perceptual_hash}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e27bb4c-04cf-4b7e-8829-9629f2c1ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create three instances of an image and compute perceptual hashes\n",
    "def create_image_instances_and_hashes(image, compute_perceptual_hash):\n",
    "    # Instance 1: Rotate the image by 15 degrees clockwise\n",
    "    rotation_15degrees_Clockwise = image.rotate(15, resample=Image.NEAREST)\n",
    "    # Compute perceptual hash for the rotated image\n",
    "    hash_rotation_15degrees_Clockwise = compute_perceptual_hash(rotation_15degrees_Clockwise)\n",
    "    \n",
    "    # Instance 2: Rotate the image by -15 degrees (counter-clockwise)\n",
    "    rotation_15degrees_CounterClockwise = image.rotate(-15, resample=Image.NEAREST)\n",
    "    # Compute perceptual hash for the rotated image\n",
    "    hash_rotation_15degrees_CounterClockwise = compute_perceptual_hash(rotation_15degrees_CounterClockwise)\n",
    "    \n",
    "    # Instance 3: Apply a shear transformation with minimal difference\n",
    "    width, height = image.size\n",
    "    shear_matrix = (1, 0.05, 0, 0.05, 1, 0)  # Minimal shearing transformation matrix\n",
    "    Shear_Low_Difference = image.transform((width, height), Image.AFFINE, shear_matrix, resample=Image.NEAREST)\n",
    "    # Compute perceptual hash for the sheared image\n",
    "    hash_Shear_Low_Difference = compute_perceptual_hash(Shear_Low_Difference)\n",
    "    \n",
    "    return {\n",
    "        \"rotation_15degrees_Clockwise\": hash_rotation_15degrees_Clockwise,\n",
    "        \"rotation_15degrees_CounterClockwise\": hash_rotation_15degrees_CounterClockwise,\n",
    "        \"Shear_Low_Difference\": hash_Shear_Low_Difference\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa12710-b140-462c-9c50-267232c028ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Perceptual HashValue_rotation_15degrees_Clockwise</th>\n",
       "      <th>Perceptual HashValue_rotation_15degrees_CounterClockwise</th>\n",
       "      <th>Perceptual HashValue_Shear_Low_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\APPU SELVA\\temp\\DSC_0172.JPG</td>\n",
       "      <td>3e3383858181c77c</td>\n",
       "      <td>d8ddc3838581e13e</td>\n",
       "      <td>bb9383818181cffc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\APPU SELVA\\temp\\DSC_0769.JPG</td>\n",
       "      <td>0e70270737172720</td>\n",
       "      <td>302f0335272f4f0e</td>\n",
       "      <td>272104272f2f2f06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\APPU SELVA\\temp\\DSC_0777.JPG</td>\n",
       "      <td>0f2e3307b7971710</td>\n",
       "      <td>10978fb1372f2f0e</td>\n",
       "      <td>272f80a7272f2f04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FileName  \\\n",
       "0  C:\\APPU SELVA\\temp\\DSC_0172.JPG   \n",
       "1  C:\\APPU SELVA\\temp\\DSC_0769.JPG   \n",
       "2  C:\\APPU SELVA\\temp\\DSC_0777.JPG   \n",
       "\n",
       "  Perceptual HashValue_rotation_15degrees_Clockwise  \\\n",
       "0                                  3e3383858181c77c   \n",
       "1                                  0e70270737172720   \n",
       "2                                  0f2e3307b7971710   \n",
       "\n",
       "  Perceptual HashValue_rotation_15degrees_CounterClockwise  \\\n",
       "0                                   d8ddc3838581e13e         \n",
       "1                                   302f0335272f4f0e         \n",
       "2                                   10978fb1372f2f0e         \n",
       "\n",
       "  Perceptual HashValue_Shear_Low_Difference  \n",
       "0                          bb9383818181cffc  \n",
       "1                          272104272f2f2f06  \n",
       "2                          272f80a7272f2f04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the data for the table\n",
    "hash_table_data = []\n",
    "\n",
    "# Loop through each image and compute the perceptual hashes for its instances\n",
    "for image_path in image_paths:\n",
    "    with Image.open(image_path) as img:\n",
    "        # Create the instances and compute perceptual hashes\n",
    "        image_hashes = create_image_instances_and_hashes(img, compute_perceptual_hash)\n",
    "        \n",
    "        # Add the data to the table\n",
    "        hash_table_data.append({\n",
    "            \"FileName\": image_path,\n",
    "            \"Perceptual HashValue_rotation_15degrees_Clockwise\": image_hashes[\"rotation_15degrees_Clockwise\"],\n",
    "            \"Perceptual HashValue_rotation_15degrees_CounterClockwise\": image_hashes[\"rotation_15degrees_CounterClockwise\"],\n",
    "            \"Perceptual HashValue_Shear_Low_Difference\": image_hashes[\"Shear_Low_Difference\"]\n",
    "        })\n",
    "\n",
    "# Convert the data into a pandas DataFrame for easy viewing\n",
    "df = pd.DataFrame(hash_table_data)\n",
    "\n",
    "# Display the table\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe73f55-e0f7-4d92-b31d-37093952b68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\jupyter anaconder\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\jupyter anaconder\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\jupyter anaconder\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271ed269-6745-4a57-8f11-972a524f253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_metadata_db.py\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e141ec0-39b7-4fd4-b72a-58c607a8bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base class for the ORM\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the database schema\n",
    "class ImageMetadata(Base):\n",
    "    __tablename__ = 'image_metadata'\n",
    "\n",
    "    ID = Column(Integer, primary_key=True, nullable=False)\n",
    "    filename = Column(String, nullable=False)\n",
    "    cryptographic_hash = Column(String, nullable=False)\n",
    "    perceptual_hash = Column(String, nullable=False)\n",
    "    file_location = Column(String, nullable=False)\n",
    "    file_size = Column(Float, nullable=False)\n",
    "    image_width = Column(Integer, nullable=False)\n",
    "    image_height = Column(Integer, nullable=False)\n",
    "    file_creation_date = Column(DateTime, nullable=False)\n",
    "    file_extension = Column(String, nullable=False)\n",
    "    perceptual_hash_rotation_15degrees_cw = Column(String, nullable=False)\n",
    "    perceptual_hash_rotation_15degrees_ccw = Column(String, nullable=False)\n",
    "    perceptual_hash_shear_low_difference = Column(String, nullable=False)\n",
    "\n",
    "# Initialize the database\n",
    "def initialize_db(db_name):\n",
    "    engine = create_engine(f'sqlite:///{db_name}')  # SQLite database\n",
    "    Base.metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    return Session()\n",
    "\n",
    "\n",
    "def check_db_creation(db_name):\n",
    "    # Check if the database file exists\n",
    "    db_path = os.path.abspath(db_name)\n",
    "    if os.path.exists(db_path):\n",
    "        print(f\"Database '{db_name}' exists at: {db_path}\")\n",
    "    else:\n",
    "        print(f\"Database '{db_name}' does not exist. It may not have been created yet.\")\n",
    "    return db_path\n",
    "\n",
    "\n",
    "# Function to add image metadata\n",
    "def insert_image_metadata(session, image_metadata):\n",
    "    session.add(image_metadata)\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "783cd276-5953-4e3d-8e16-a4f19fa8db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'image_metadata.db' exists at: C:\\Users\\selva\\image_metadata.db\n",
      "Image Path: C:\\APPU SELVA\\temp\\DSC_0172.JPG, Cryptographic Hash: 9e422052fd039a43db88ce1a96759febfa60fee2111a7081b3fcb187c035092d, Perceptual Hash: bb9383818181c1ff\n",
      "Inserted metadata for C:\\APPU SELVA\\temp\\DSC_0172.JPG into database.\n",
      "Image Path: C:\\APPU SELVA\\temp\\DSC_0769.JPG, Cryptographic Hash: 7623262c32c591f0aa586d17e0205457d2032347414dddf20035b3c216e99e35, Perceptual Hash: 0723002727272727\n",
      "Inserted metadata for C:\\APPU SELVA\\temp\\DSC_0769.JPG into database.\n",
      "Image Path: C:\\APPU SELVA\\temp\\DSC_0777.JPG, Cryptographic Hash: 7c5c213df376f81da6002acca512972b671f2d7e11e20aae125f470a556fc25b, Perceptual Hash: 2707818617072727\n",
      "Inserted metadata for C:\\APPU SELVA\\temp\\DSC_0777.JPG into database.\n",
      "Tables in the database: dict_keys(['image_metadata'])\n",
      "(1, 'DSC_0172.JPG', '9e422052fd039a43db88ce1a96759febfa60fee2111a7081b3fcb187c035092d', 'bb9383818181c1ff', 'C:\\\\APPU SELVA\\\\temp\\\\DSC_0172.JPG', 7457167.0, 6000, 4000, datetime.datetime(2024, 12, 26, 14, 54, 32, 701142), '.jpg', '3e3383858181c77c', 'd8ddc3838581e13e', 'bb9383818181cffc')\n",
      "(2, 'DSC_0769.JPG', '7623262c32c591f0aa586d17e0205457d2032347414dddf20035b3c216e99e35', '0723002727272727', 'C:\\\\APPU SELVA\\\\temp\\\\DSC_0769.JPG', 7116746.0, 6000, 4000, datetime.datetime(2024, 12, 26, 14, 54, 32, 716764), '.jpg', '0e70270737172720', '302f0335272f4f0e', '272104272f2f2f06')\n",
      "(3, 'DSC_0777.JPG', '7c5c213df376f81da6002acca512972b671f2d7e11e20aae125f470a556fc25b', '2707818617072727', 'C:\\\\APPU SELVA\\\\temp\\\\DSC_0777.JPG', 7075229.0, 6000, 4000, datetime.datetime(2024, 12, 26, 14, 54, 32, 701142), '.jpg', '0f2e3307b7971710', '10978fb1372f2f0e', '272f80a7272f2f04')\n"
     ]
    }
   ],
   "source": [
    "# Initialize the database session\n",
    "db_name = \"image_metadata.db\"\n",
    "session = initialize_db(db_name)\n",
    "# Check if the database is created and get its path\n",
    "db_path = check_db_creation(db_name)\n",
    "\n",
    "def clear_existing_data(session):\n",
    "    session.query(ImageMetadata).delete()\n",
    "    session.commit()\n",
    "\n",
    "# Clear data before inserting new records\n",
    "clear_existing_data(session)\n",
    "\n",
    "# Function to process images and populate the database\n",
    "def process_images_and_populate_db(session, image_paths, cryptographic_hashes, perceptual_hashes, compute_perceptual_hash):\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No images found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    idx = 1\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                # Retrieve cryptographic hash \n",
    "                cryptographic_hash = cryptographic_hashes.get(image_path, compute_cryptographic_hash(image_path))\n",
    "\n",
    "\n",
    "                # Retrieve perceptual hash \n",
    "                perceptual_hash = str(perceptual_hashes.get(image_path, 'NA'))\n",
    "\n",
    "                print(f\"Image Path: {image_path}, Cryptographic Hash: {cryptographic_hash}, Perceptual Hash: {perceptual_hash}\")\n",
    "                \n",
    "                # Generate transformed perceptual hash values (mock data for now)\n",
    "                image_hashes = create_image_instances_and_hashes(img, compute_perceptual_hash)\n",
    "                ph_rot_15deg_cw = str(image_hashes.get(\"rotation_15degrees_Clockwise\", 'NA'))\n",
    "                ph_rot_15deg_ccw = str(image_hashes.get(\"rotation_15degrees_CounterClockwise\", 'NA'))\n",
    "                ph_shear_ld = str(image_hashes.get(\"Shear_Low_Difference\", 'NA'))\n",
    "\n",
    "                # Retrieve file metadata\n",
    "                file_location = os.path.abspath(image_path)\n",
    "                file_size = os.path.getsize(image_path)\n",
    "                width, height = img.size\n",
    "                creation_date = datetime.datetime.fromtimestamp(os.path.getctime(image_path))\n",
    "                file_extension = os.path.splitext(image_path)[1].lower()\n",
    "\n",
    "                # Create a metadata object\n",
    "                image_metadata = ImageMetadata(\n",
    "                    filename=os.path.basename(image_path),\n",
    "                    cryptographic_hash=cryptographic_hash,\n",
    "                    perceptual_hash=perceptual_hash,\n",
    "                    file_location=file_location,\n",
    "                    file_size=file_size,\n",
    "                    image_width=width,\n",
    "                    image_height=height,\n",
    "                    file_creation_date=creation_date,\n",
    "                    file_extension=file_extension,\n",
    "                    perceptual_hash_rotation_15degrees_cw=ph_rot_15deg_cw,\n",
    "                    perceptual_hash_rotation_15degrees_ccw=ph_rot_15deg_ccw,\n",
    "                    perceptual_hash_shear_low_difference=ph_shear_ld\n",
    "                )\n",
    "\n",
    "                # Insert into the database using the imported function\n",
    "                insert_image_metadata(session, image_metadata)\n",
    "                print(f\"Inserted metadata for {image_path} into database.\")\n",
    "                idx += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "process_images_and_populate_db(session, image_paths, cryptographic_hashes, perceptual_hashes, compute_perceptual_hash)\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db_file = \"image_metadata.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_file}\")\n",
    "\n",
    "# Reflect the database schema\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# Print available tables\n",
    "print(\"Tables in the database:\", metadata.tables.keys())\n",
    "\n",
    "# Access a specific table\n",
    "table_name = \"image_metadata\"  # Replace with your table name\n",
    "if table_name in metadata.tables:\n",
    "    table = metadata.tables[table_name]\n",
    "else:\n",
    "    raise ValueError(f\"Table '{table_name}' does not exist in the database.\")\n",
    "\n",
    "# Query the table and print results\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(table.select())\n",
    "    for row in result:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2b2cc75-65d2-4549-bb29-91194661c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database exported successfully to image_metadata_export.xlsx\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 \n",
    "def export_db_to_excel(db_name, excel_file_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    \n",
    "    # Query all data from the table\n",
    "    query = \"SELECT * FROM image_metadata\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    # Export to Excel\n",
    "    excel_file_path = f\"{excel_file_name}.xlsx\"\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Database exported successfully to {excel_file_path}\")\n",
    "    return excel_file_path\n",
    "\n",
    "# Export the database to an Excel file\n",
    "db_name = 'image_metadata.db'\n",
    "excel_file_name = 'image_metadata_export'\n",
    "excel_file_path = export_db_to_excel(db_name, excel_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb3ca5-79cd-4db2-9ec5-197d61c3d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to store perceptual hash data\n",
    "# perceptual_hash_data = {}\n",
    "\n",
    "# # Loop through images and populate the dictionary\n",
    "# for image_path in image_paths:\n",
    "#     try:\n",
    "#         # Retrieve the cryptographic hash\n",
    "#         cryptographic_hash = cryptographic_hashes.get(image_path, 'NA')\n",
    "        \n",
    "#         # Retrieve the perceptual hash\n",
    "#         perceptual_hash = str(perceptual_hashes.get(image_path, 'NA'))\n",
    "        \n",
    "#         # Retrieve transformed perceptual hashes\n",
    "#         with Image.open(image_path) as img:\n",
    "#             image_hashes = create_image_instances_and_hashes(img, compute_perceptual_hash)\n",
    "#             ph_rot_15deg_cw = str(image_hashes.get(\"rotation_15degrees_Clockwise\", 'N/A'))\n",
    "#             ph_rot_15deg_ccw = str(image_hashes.get(\"rotation_15degrees_CounterClockwise\", 'N/A'))\n",
    "#             ph_shear_ld = str(image_hashes.get(\"Shear_Low_Difference\", 'N/A'))\n",
    "        \n",
    "#         # Store the data in the dictionary\n",
    "#         perceptual_hash_data[cryptographic_hash] = {\n",
    "#             \"Perceptual_Hash\": perceptual_hash,\n",
    "#             \"Perceptual_Hash_rotation_15degrees_Clockwise\": ph_rot_15deg_cw,\n",
    "#             \"Perceptual_Hash_rotation_15degrees_CounterClockwise\": ph_rot_15deg_ccw,\n",
    "#             \"Perceptual_Hash_Shear_Low_Difference\": ph_shear_ld\n",
    "#         }\n",
    "        \n",
    "#         print(f\"Stored perceptual hash data for {image_path}.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "# # Display the resulting dictionary\n",
    "# print(\"Perceptual Hash Data Dictionary:\")\n",
    "# print(perceptual_hash_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8cc7e-0784-4d53-bb93-8afb65cd670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store perceptual hash data\n",
    "perceptual_hash_data = {}\n",
    "\n",
    "# Loop through images and populate the dictionary\n",
    "for image_path in image_paths:\n",
    "    try:\n",
    "        # Use the filename as the primary key (you can extract it from the image_path)\n",
    "        filename = image_path.split(\"\\\\\")[-1]  # Extracts the filename from the path\n",
    "        \n",
    "        # Retrieve the  perceptual hash\n",
    "        \n",
    "        perceptual_hash = str(perceptual_hashes.get(image_path, 'NA'))\n",
    "        \n",
    "        # Retrieve transformed perceptual hashes\n",
    "        with Image.open(image_path) as img:\n",
    "            image_hashes = create_image_instances_and_hashes(img, compute_perceptual_hash)\n",
    "            ph_rot_15deg_cw = str(image_hashes.get(\"rotation_15degrees_Clockwise\", 'N/A'))\n",
    "            ph_rot_15deg_ccw = str(image_hashes.get(\"rotation_15degrees_CounterClockwise\", 'N/A'))\n",
    "            ph_shear_ld = str(image_hashes.get(\"Shear_Low_Difference\", 'N/A'))\n",
    "        \n",
    "        # Store the data in the dictionary, using the filename as the key\n",
    "        perceptual_hash_data[filename] = {\n",
    "            \"Perceptual_Hash\": perceptual_hash,\n",
    "            \"Perceptual_Hash_rotation_15degrees_Clockwise\": ph_rot_15deg_cw,\n",
    "            \"Perceptual_Hash_rotation_15degrees_CounterClockwise\": ph_rot_15deg_ccw,\n",
    "            \"Perceptual_Hash_Shear_Low_Difference\": ph_shear_ld\n",
    "        }\n",
    "        \n",
    "        print(f\"Stored perceptual hash data for {filename}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "# Display the resulting dictionary\n",
    "print(\"Perceptual Hash Data Dictionary:\")\n",
    "print(perceptual_hash_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052ef1d-3c22-4062-9c5a-fa6853542a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Hamming distance\n",
    "def calculate_hamming_distance(hash1, hash2):\n",
    "    return hash1 - hash2  # Replace with actual logic for Hamming distance\n",
    "\n",
    "# Function to compute pairwise Hamming distance for all images\n",
    "def compute_pairwise_hamming_distances(perceptual_hash_data):\n",
    "    pairwise_distances = {}\n",
    "\n",
    "    # Get a list of filenames (keys) in the dictionary\n",
    "    filenames = list(perceptual_hash_data.keys())\n",
    "    \n",
    "    # Iterate through each pair of images\n",
    "    for i in range(len(filenames)):\n",
    "        for j in range(i + 1, len(filenames)):\n",
    "            image_A = filenames[i]\n",
    "            image_B = filenames[j]\n",
    "            \n",
    "            # Extract perceptual hash values for image A and B\n",
    "            ph_A = perceptual_hash_data[image_A]\n",
    "            ph_B = perceptual_hash_data[image_B]\n",
    "            \n",
    "            # List of perceptual hashes for image A and image B\n",
    "            ph_A_values = [\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_rotation_15degrees_Clockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_rotation_15degrees_CounterClockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_Shear_Low_Difference\"])\n",
    "            ]\n",
    "            \n",
    "            ph_B_values = [\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_rotation_15degrees_Clockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_rotation_15degrees_CounterClockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_Shear_Low_Difference\"])\n",
    "            ]\n",
    "            \n",
    "            # Compute pairwise Hamming distances between A and B's perceptual hashes\n",
    "            min_distance = float('inf')  # Start with a large value\n",
    "            \n",
    "            # Compute all pairwise distances between A and B's perceptual hashes\n",
    "            for ph_A_value in ph_A_values:\n",
    "                for ph_B_value in ph_B_values:\n",
    "                    distance = calculate_hamming_distance(ph_A_value, ph_B_value)\n",
    "                    min_distance = min(min_distance, distance)\n",
    "            \n",
    "            # Store the minimum distance for the current pair of images\n",
    "            pairwise_distances[(image_A, image_B)] = min_distance\n",
    "\n",
    "    return pairwise_distances\n",
    "\n",
    "# Compute pairwise Hamming distances\n",
    "pairwise_hamming_distances = compute_pairwise_hamming_distances(perceptual_hash_data)\n",
    "\n",
    "# Display the pairwise Hamming distances\n",
    "print(\"Pairwise Hamming Distances:\")\n",
    "for (image_A, image_B), min_distance in pairwise_hamming_distances.items():\n",
    "    print(f\"Minimum Hamming Distance between {image_A} and {image_B}: {min_distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4462c-cd8d-4fe5-a8ef-857c00df6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Hamming distance (same as before)\n",
    "def calculate_hamming_distance(hash1, hash2):\n",
    "    return hash1 - hash2  # Replace with actual logic for Hamming distance\n",
    "\n",
    "# Function to compute pairwise Hamming distance for all images (full matrix)\n",
    "def compute_pairwise_hamming_distances(perceptual_hash_data):\n",
    "    pairwise_distances = {}\n",
    "\n",
    "    # Get a list of filenames (keys) in the dictionary\n",
    "    filenames = list(perceptual_hash_data.keys())\n",
    "    \n",
    "    # Initialize a distance matrix\n",
    "    distance_matrix = np.zeros((len(filenames), len(filenames)))\n",
    "    \n",
    "    # Iterate through each pair of images and compute distances\n",
    "    for i in range(len(filenames)):\n",
    "        for j in range(i + 1, len(filenames)):\n",
    "            image_A = filenames[i]\n",
    "            image_B = filenames[j]\n",
    "            \n",
    "            # Extract perceptual hash values for image A and B\n",
    "            ph_A = perceptual_hash_data[image_A]\n",
    "            ph_B = perceptual_hash_data[image_B]\n",
    "            \n",
    "            # List of perceptual hashes for image A and image B\n",
    "            ph_A_values = [\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_rotation_15degrees_Clockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_rotation_15degrees_CounterClockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_A[\"Perceptual_Hash_Shear_Low_Difference\"])\n",
    "            ]\n",
    "            \n",
    "            ph_B_values = [\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_rotation_15degrees_Clockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_rotation_15degrees_CounterClockwise\"]),\n",
    "                imagehash.hex_to_hash(ph_B[\"Perceptual_Hash_Shear_Low_Difference\"])\n",
    "            ]\n",
    "            \n",
    "            # Compute pairwise Hamming distances between A and B's perceptual hashes\n",
    "            min_distance = float('inf')  # Start with a large value\n",
    "            \n",
    "            # Compute all pairwise distances between A and B's perceptual hashes\n",
    "            for ph_A_value in ph_A_values:\n",
    "                for ph_B_value in ph_B_values:\n",
    "                    distance = calculate_hamming_distance(ph_A_value, ph_B_value)\n",
    "                    min_distance = min(min_distance, distance)\n",
    "            \n",
    "            # Store the minimum distance for the current pair of images in the distance matrix\n",
    "            distance_matrix[i, j] = min_distance\n",
    "            distance_matrix[j, i] = min_distance  # Matrix is symmetric\n",
    "\n",
    "    return filenames, distance_matrix\n",
    "\n",
    "# Compute pairwise Hamming distances\n",
    "filenames, pairwise_hamming_distances = compute_pairwise_hamming_distances(perceptual_hash_data)\n",
    "\n",
    "# Mask the lower triangular part of the matrix (set NaN for lower triangle)\n",
    "mask_lower = np.tril(np.ones_like(pairwise_hamming_distances, dtype=bool), k=0)  # Mask lower triangle\n",
    "pairwise_hamming_distances[mask_lower] = np.nan  # Set lower triangle to NaN (no annotation)\n",
    "\n",
    "# Plot the distance matrix as a heatmap with binary color map\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Set the color map to 'binary' and annotate only for the lower triangle\n",
    "sns.heatmap(pairwise_hamming_distances, \n",
    "            xticklabels=filenames, \n",
    "            yticklabels=filenames, \n",
    "            cmap=\"binary\", \n",
    "            annot=True, \n",
    "            annot_kws={'size': 10}, \n",
    "            cbar=True, \n",
    "            mask=mask_lower, \n",
    "            square=True)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title(\"Pairwise Minimum Hamming Distances between Images\")\n",
    "plt.xlabel(\"Image Filename\")\n",
    "plt.ylabel(\"Image Filename\")\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965688f-be0b-4161-9b8a-16a58227fa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
